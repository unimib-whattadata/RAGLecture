{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Retrieval Augmented Generation (RAG) System with LangChain and ICD-11 Data\n",
        "\n",
        "This Colab notebook demonstrates how to build a RAG system using LangChain to answer questions based on the International Classification of Diseases, 11th Revision (ICD-11) data.\n",
        "\n",
        "**Objectives:**\n",
        "* Understand the concept of Retrieval Augmented Generation (RAG).\n",
        "* Learn how to acquire and preprocess external knowledge (ICD-11 data).\n",
        "* Utilize LangChain to integrate various components: Document Loaders, Text Splitters, Embedding Models, Vector Stores, and Language Models.\n",
        "* Build and query a simple RAG chain.\n"
      ],
      "metadata": {
        "id": "MYdeL8ij-0Ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Prerequisites\n",
        "\n",
        "To follow along, you will need:\n",
        "\n",
        "**Google API Key:**\n",
        "1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)\n",
        "2. Click \"Get API Key\" or \"Create API Key in new project\"\n",
        "3. Copy the generated API key\n",
        "\n",
        "**ICD-11 Chapter 6 Dataset:**\n",
        "1. Go to [Drive](https://drive.google.com/file/d/1ThIsNf1iuns9wlMZmBHOWRI9E6FiVgjQ/view?usp=drive_link)\n",
        "2. Upload it here in colab, go to file section, just add it to the root folder"
      ],
      "metadata": {
        "id": "h2RktdSy-2XK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODE 1 - Setting up libraries ##\n",
        "\n",
        "We use !pip to install LangChain and its related packages, including the integration for Google's AI models and the Chroma vector store"
      ],
      "metadata": {
        "id": "1Zi_CU84-_a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install langchain langchain-community\n",
        "!pip install pandas\n",
        "!pip install langchain-chroma\n",
        "!pip install langchain-google-genai\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")"
      ],
      "metadata": {
        "id": "dLI3ygPT_Kz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODE 2 - Loading external data\n",
        "\n",
        "We will load the ICD-11 data directly from the provided `icdchapter6.csv` file. This file contains ICD-11 codes, titles, and definitions, separated by semicolons."
      ],
      "metadata": {
        "id": "IkrrQGPM_NH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "def load_icd11_from_csv(file_path: str) -> list[Document]:\n",
        "    \"\"\"\n",
        "    Loads ICD-11 data from a CSV file and converts it into LangChain Document objects.\n",
        "    Assumes the CSV has columns like 'Code', 'Title', 'Definition'.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        list[Document]: A list of LangChain Document objects.\n",
        "    \"\"\"\n",
        "    print(f\"Loading ICD-11 data from CSV: '{file_path}'...\")\n",
        "    try:\n",
        "        # Read the CSV file using pandas, specifying the delimiter\n",
        "        # Assuming the CSV has headers like 'Code', 'Title', 'Definition'\n",
        "\n",
        "        print(f\"Successfully loaded {len(icd_documents)} ICD-11 entries from CSV.\")\n",
        "        return icd_documents\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: CSV file not found at '{file_path}'. Please ensure the file is uploaded.\")\n",
        "        return []\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Missing expected column in CSV: {e}. Please check CSV headers.\")\n",
        "        print(\"Expected columns: 'Code', 'Title', 'Definition'\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while reading the CSV: {e}\")\n",
        "        return []\n",
        "\n",
        "# Load ICD-11 documents from the uploaded CSV file\n",
        "# Ensure 'icdchapter6.csv' is uploaded to your Colab environment\n",
        "icd11_documents = load_icd11_from_csv('icdchapter6.csv')\n",
        "\n",
        "if icd11_documents:\n",
        "    print(\"\\nSample ICD-11 Document (first 100 characters):\")\n",
        "    print(icd11_documents[0].page_content[:100], \"...\")\n",
        "    print(\"\\nMetadata example:\")\n",
        "    print(icd11_documents[0].metadata)\n",
        "else:\n",
        "    print(\"Failed to load ICD-11 documents from CSV. Please check the file path and content.\")"
      ],
      "metadata": {
        "id": "dqJJ4L7j_OP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODE - Processing Documents: No Text Splitting\n",
        "\n",
        "As each row in the CSV represents a complete disorder entry and should not be split, we will treat each loaded document as a single chunk. This means we will not apply any further text splitting."
      ],
      "metadata": {
        "id": "J8M12pw8_kAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As requested, each document (representing a row/disorder) will be treated as a single chunk.\n",
        "icd11_chunks = icd11_documents\n",
        "\n",
        "print(f\"\\nOriginal documents count (now also chunk count): {len(icd11_documents)}\")\n",
        "print(f\"Each document is now treated as a single chunk.\")\n",
        "\n",
        "if icd11_chunks:\n",
        "    print(\"\\nSample chunk (first 100 characters):\")\n",
        "    print(icd11_chunks[0].page_content[:100], \"...\")\n",
        "    print(\"\\nSample chunk metadata:\")\n",
        "    print(icd11_chunks[0].metadata)\n",
        "else:\n",
        "    print(\"No chunks available. Please ensure ICD-11 documents were loaded correctly.\")"
      ],
      "metadata": {
        "id": "LRsIVKMK_kmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODE 3 - Generating Embeddings\n",
        "\n",
        "Embeddings are numerical representations of text that capture semantic meaning. We'll use these embeddings to find semantically similar chunks when a user asks a question. `GoogleGenerativeAIEmbeddings` will convert our text chunks into vectors."
      ],
      "metadata": {
        "id": "O9lZlAJa_nnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "# Initialize the embedding model\n",
        "# The model name 'models/embedding-001' is suitable for generating text embeddings.\n",
        "# It uses the API key set in the GOOGLE_API_KEY environment variable.\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "print(\"Embedding model initialized.\")\n",
        "# You can optionally test an embedding\n",
        "# sample_embedding = embeddings.embed_query(\"What is hypertension?\")\n",
        "# print(f\"Sample embedding dimension: {len(sample_embedding)}\")"
      ],
      "metadata": {
        "id": "RZSg3FyO_nT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## CODE 4 - Creating or Loading a Persistent Vector Store\n",
        "\n",
        "A vector store (or vector database) stores the embeddings and allows for efficient similarity search.\n",
        "We'll use `Chroma` and configure it to persist data to disk. This means if you run this notebook again,\n",
        "it will load the existing vector store instead of re-embedding all documents, saving time."
      ],
      "metadata": {
        "id": "s0g2xKK1_qy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "import os\n",
        "\n",
        "# Define the directory where the vector store will be persisted\n",
        "persist_directory = \"./chroma_db\"\n",
        "\n",
        "# Check if the vector store already exists\n",
        "if os.path.exists(persist_directory) and os.listdir(persist_directory):\n",
        "\n",
        "else:\n",
        "\n",
        "\n",
        "# To make the vectorstore a retriever that can be used in the RAG chain:\n",
        "retriever = vectorstore.as_retriever()\n",
        "print(\"Retriever created from the vector store.\")"
      ],
      "metadata": {
        "id": "59nrU0-y_qlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODE 5 - Building the RAG Chain\n",
        "\n",
        "Now, we'll assemble the RAG chain using LangChain. The chain will perform the following steps:\n",
        "1.  **Retrieve:** Given a user query, use the `retriever` to find the most relevant chunks from our ICD-11 vector store.\n",
        "2.  **Stuff:** Combine these retrieved chunks with the original query into a single prompt for the Language Model.\n",
        "3.  **Generate:** The Language Model generates a response based on the combined prompt.\n",
        "\n",
        "We'll use LangChain Expression Language (LCEL) for a clear and flexible chain construction."
      ],
      "metadata": {
        "id": "xjhxnOvy_0X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Initialize the Language Model (LLM)\n",
        "# Changed model to 'gemma-3-1b-it' as requested.\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemma-3-1b-it\", temperature=0.7)\n",
        "\n",
        "# Define the prompt template for the LLM\n",
        "# The prompt instructs the LLM to act as a helpful assistant and answer questions\n",
        "# based on the provided context, stating if it doesn't know.\n",
        "template = \"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Construct the RAG chain using LCEL\n",
        "# The chain flows from:\n",
        "# 1. 'question' and 'context' inputs. 'context' is populated by the retriever.\n",
        "# 2. These are passed to the prompt.\n",
        "# 3. The prompt is passed to the LLM.\n",
        "# 4. The LLM's output is parsed into a string.\n",
        "rag_chain = ()\n",
        "\n",
        "print(\"RAG chain constructed.\")"
      ],
      "metadata": {
        "id": "9rIjfJk-_069"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Demonstration & Evaluation\n",
        "\n",
        "Now, let's test our RAG system with some queries related to medical conditions."
      ],
      "metadata": {
        "id": "nF2RghwRAvA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_rag_system(query: str):\n",
        "    \"\"\"\n",
        "    Asks a question to the RAG system and prints the answer.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "# Example Queries\n",
        "ask_rag_system(\"What is the ICD-11 code and definition for 'Dissociative identity disorder'?\")\n",
        "ask_rag_system(\"What is the capital of France?\") # This query should ideally result in \"I don't know\" as it's outside the ICD-11 context.\n",
        "ask_rag_system(\"What is the ICD-11 code for 'Anxiety'?\") # Test a term that might be less prevalent if max_results was small."
      ],
      "metadata": {
        "id": "S2kIDhYUAvlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion and Next Steps\n",
        "\n",
        "You have successfully built a basic RAG system using LangChain, drawing information from ICD-11 data.\n",
        "\n",
        "**Key Learnings:**\n",
        "* How to load and prepare unstructured data for RAG.\n",
        "* The role of text splitting and embeddings.\n",
        "* Creating and using a vector store (Chroma).\n",
        "* Connecting an LLM and retriever to form a RAG chain.\n",
        "\n",
        "**Potential Improvements and Further Exploration:**\n",
        "* **Larger Dataset:** Integrate with the full WHO ICD-11 API (requires authentication and more robust data handling) or download a larger pre-processed dataset if available publicly.\n",
        "* **Advanced Text Splitting:** Experiment with different `TextSplitter` strategies or add metadata to chunks for improved retrieval.\n",
        "* **Hybrid Search:** Combine vector similarity search with keyword-based search for better retrieval performance.\n",
        "* **Reranking:** Implement a reranking step after initial retrieval to ensure the most relevant documents are passed to the LLM.\n",
        "* **Evaluation Metrics:** Set up evaluation metrics to assess the performance of your RAG system (e.g., faithfulness, relevance).\n",
        "* **User Interface:** Build a simple web interface (e.g., using Streamlit or Gradio) to interact with the RAG system.\n",
        "* **Chat History:** Extend the RAG chain to incorporate conversational history for more coherent multi-turn interactions."
      ],
      "metadata": {
        "id": "0zPiTf5KA3oP"
      }
    }
  ]
}